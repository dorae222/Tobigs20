{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d2StPehwLMat"
   },
   "source": [
    "# Tobig's 19기 2주차 Optimization 과제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DKIX8PqcLMaw"
   },
   "source": [
    "# Gradient Descent 구현하기\n",
    "\n",
    "### 1)\"...\"표시되어 있는 빈 칸을 채워주세요\n",
    "### 2)강의내용과 코드에 대해 공부한 내용을 마크마운 또는 주석으로 설명해주세요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6DNHHXfLMax"
   },
   "source": [
    "## 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EP3O4xptLMay"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oByQ9wXHLMay"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>bias</th>\n",
       "      <th>experience</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>63000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>76000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label  bias  experience  salary\n",
       "0      1     1         0.7   48000\n",
       "1      0     1         1.9   48000\n",
       "2      1     1         2.5   60000\n",
       "3      0     1         4.2   63000\n",
       "4      0     1         6.0   76000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('assignment_2.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ubOR3hWGLMaz"
   },
   "source": [
    "## Train Test 데이터 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "IySSjlizLMaz"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "075EQI1bLMa0"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:, 0], test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "O8Ht5u8kLMa1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 3), (50, 3), (150,), (50,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hYmxND_xLMa2"
   },
   "source": [
    "## Scaling\n",
    "\n",
    "experience와 salary의 단위, 평균, 분산이 크게 차이나므로 scaler를 사용해 단위를 맞춰줍니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "UI0Xy0gHLMa3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>experience</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.187893</td>\n",
       "      <td>-1.143335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.185555</td>\n",
       "      <td>0.043974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.310938</td>\n",
       "      <td>-0.351795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.629277</td>\n",
       "      <td>-1.341220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.308600</td>\n",
       "      <td>0.043974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bias  experience    salary\n",
       "0     1    0.187893 -1.143335\n",
       "1     1    1.185555  0.043974\n",
       "2     1   -0.310938 -0.351795\n",
       "3     1   -1.629277 -1.341220\n",
       "4     1   -1.308600  0.043974"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "bias_train = X_train[\"bias\"]\n",
    "bias_train = bias_train.reset_index()[\"bias\"]\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns = X_train.columns)\n",
    "X_train[\"bias\"] = bias_train\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xD7L7RwZLMa3"
   },
   "source": [
    "이때 scaler는 X_train에 fit 해주시고, fit한 scaler를 X_test에 적용시켜줍니다.  \n",
    "똑같이 X_test에다 fit하면 안돼요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "xBsUSCGGLMa3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>experience</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.344231</td>\n",
       "      <td>-0.615642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.508570</td>\n",
       "      <td>0.307821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.310938</td>\n",
       "      <td>0.571667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.363709</td>\n",
       "      <td>1.956862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.987923</td>\n",
       "      <td>-0.747565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bias  experience    salary\n",
       "0     1   -1.344231 -0.615642\n",
       "1     1    0.508570  0.307821\n",
       "2     1   -0.310938  0.571667\n",
       "3     1    1.363709  1.956862\n",
       "4     1   -0.987923 -0.747565"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_test = X_test[\"bias\"]\n",
    "bias_test = bias_test.reset_index()[\"bias\"]\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns = X_test.columns)\n",
    "X_test[\"bias\"] = bias_test\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "m9sP3nzlLMa4"
   },
   "outputs": [],
   "source": [
    "# parameter 개수\n",
    "N = len(X_train.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "qz7xz9dbLMa4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.55421524, 0.3919842 , 0.57721591])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 초기 parameter들을 임의로 설정해줍니다.\n",
    "parameters = np.array([random.random() for i in range(N)])\n",
    "random_parameters = parameters.copy()\n",
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QINz-EAKLMa4"
   },
   "source": [
    "### * LaTeX   \n",
    "\n",
    "Jupyter Notebook은 LaTeX 문법으로 수식 입력을 지원하고 있습니다.  \n",
    "LaTeX문법으로 아래의 수식을 완성해주세요  \n",
    "http://triki.net/apps/3466  \n",
    "https://jjycjnmath.tistory.com/117"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D2DsTfXuLMa5"
   },
   "source": [
    "## Dot product\n",
    "$z = X_i \\theta$\n",
    "- 풀어쓰면\n",
    "### $z = X_{1}\\theta_{1}+z + X_{2}\\theta_{2}+z + X_{3}\\theta_{3}+\\varepsilon,\\varepsilon \\sim N(0,1)$\n",
    "    - $\\varepsilon$은 결과에 거의 영향을 주지 않으므로 생략"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "2y05lS6xLMa5"
   },
   "outputs": [],
   "source": [
    "def dot_product(X, parameters):\n",
    "    z = 0\n",
    "    for i in range(len(parameters)):\n",
    "        z += X[i] * parameters[i]\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fOGPEhtOLMa5"
   },
   "source": [
    "## Logistic Function\n",
    "\n",
    "$p = \\frac{1}{1+e^{-z}}$\n",
    "\n",
    "### $p = \\frac{1}{1 + e^{-(X_{1}\\theta_{1} + X_{2}\\theta_{2} + X_{3}\\theta_{3} + \\varepsilon)}},\\varepsilon \\sim N(0,1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "2awM57u5LMa5"
   },
   "outputs": [],
   "source": [
    "def logistic(X, parameters):\n",
    "    z = dot_product(X, parameters)\n",
    "    p = 1 / (1 + np.exp(-z))    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "WVaZEwrdLMa5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7396820921083802"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic(X_train.iloc[1], parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E6cXHl8bLMa6"
   },
   "source": [
    "## Object function\n",
    "\n",
    "Object Function : 목적함수는 Gradient Descent를 통해 최적화 하고자 하는 함수입니다.  \n",
    "<br>\n",
    "선형 회귀의 목적함수\n",
    "## $l(\\theta) = \\frac{1}{2}\\Sigma(y_i - \\theta^{T}X_i)^2$  \n",
    "참고) $\\hat{y_i} = \\theta^{T}X_i$\n",
    "  \n",
    "로지스틱 회귀의 목적함수를 작성해주세요  \n",
    "(선형 회귀의 목적함수처럼 강의에 나온대로 작성해주세요. 평균을 고려하는 것은 뒤에 코드에서 수행합니다)\n",
    "## $l(p)= \\frac{1}{2}\\Sigma(-y_{i}log(\\theta^{T}X_i)-(1-y_{i})log(1-\\theta^{T}X_i))$\n",
    "$l(p)= \\frac{1}{2}\\Sigma(-y_{i}log(\\hat{y}_{i}))-(1-y_{i})log(1-\\hat{y}_{i}))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "FnGRAur3LMa6"
   },
   "outputs": [],
   "source": [
    "def minus_log_cross_entropy_i(X, y, parameters):\n",
    "    p = logistic(X, parameters)\n",
    "    loss = (-(y * np.log(p) + (1 - y) * np.log(1 - p)))/2\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "C922eXYyLMa6"
   },
   "outputs": [],
   "source": [
    "def mse_i(X, y, parameters):\n",
    "    y_hat = dot_product(X, parameters)\n",
    "    loss = (y - y_hat) ** 2 / 2\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "0j-MhGkyLMa6"
   },
   "outputs": [],
   "source": [
    "def batch_loss(X_set, y_set, parameters, loss_function, n): #n:현재 배치의 데이터 수\n",
    "    loss = 0\n",
    "    for i in range(X_set.shape[0]):\n",
    "        X = X_set.iloc[i,:]\n",
    "        y = y_set.iloc[i]\n",
    "        loss += loss_function(X, y, parameters)\n",
    "    loss = loss/n #loss 평균값으로 계산\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "uSkPS5olLMa7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5720069869715811"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_loss(X_test, y_test, parameters, minus_log_cross_entropy_i, len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ACLi9vCyLMa7"
   },
   "source": [
    "## Gradient\n",
    "위의 선형회귀의 목적함수 $l(\\theta)$와 로지스틱회귀의 목적함수 $l(p)$의 gradient를 작성해주세요  \n",
    "(위의 목적함수를 참고해서 작성해주세요 = 평균을 고려하는 것은 뒤에 코드에서 수행합니다)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "caMA-f00LMa7"
   },
   "source": [
    "## ${\\partial\\over{\\partial \\theta_j}}l(\\theta)=$ $\\sum (y_i - \\theta^{T}X_i)(-X_{ij})$\n",
    "## ${\\partial\\over{\\partial \\theta_j}}l(p)=$ $\\sum (y_i - p_i)(-X_{ij})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "apZ0Miz5LMa7"
   },
   "outputs": [],
   "source": [
    "def get_gradient_ij(X, y, parameters, j, model):\n",
    "    if model == 'linear':\n",
    "        y_hat = dot_product(X, parameters)\n",
    "        gradient = -(y - y_hat) * X[j]\n",
    "    else:  # model == 'logistic'\n",
    "        p = logistic(X, parameters)\n",
    "        gradient = (p - y) * X[j]\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "XXBe6q8gLMa7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.09545351786188805"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_gradient_ij(X_train.iloc[0,:], y_train.iloc[0], parameters, 1, 'logistic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"./img/배치알고리즘구현.png\" width=\"500\"/><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wTfzKh_nLMa7"
   },
   "source": [
    "## Batch Gradient\n",
    "하나의 배치 (X_set, y_set)에 대해 기울기를 구하는 코드를 작성해주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Qby2_X1vLMa7"
   },
   "outputs": [],
   "source": [
    "def batch_gradient(X_set, y_set, parameters, model):\n",
    "    gradients = [0 for _ in range(len(parameters))]\n",
    "    \n",
    "    for i in range(X_set.shape[0]):\n",
    "        X = X_set.iloc[i,:]\n",
    "        y = y_set.iloc[i]\n",
    "        for j in range(len(parameters)):\n",
    "            gradients[j] += get_gradient_ij(X, y, parameters, j, model)\n",
    "    \n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "rHxBS5RnLMa8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[49.932474511542004, 7.2054605600290875, 40.3202482589601]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients1 = batch_gradient(X_train, y_train, parameters, 'logistic')\n",
    "gradients1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQnlDboALMa8"
   },
   "source": [
    "## mini-batch\n",
    "인덱스로 미니 배치 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "LgnfT6eHLMa8"
   },
   "outputs": [],
   "source": [
    "def batch_idx(X_train, batch_size):\n",
    "    N = len(X_train)\n",
    "    nb = (N // batch_size)+1 #number of batch\n",
    "    idx = np.array([i for i in range(N)])\n",
    "    idx_list = [idx[i*batch_size:(i+1)*batch_size] for i in range(nb) if len(idx[i*batch_size:(i+1)*batch_size]) != 0]\n",
    "    return idx_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9S9fk1UTLMa8"
   },
   "source": [
    "batch_idx 함수에 대한 설명을 batch_size와 함께 간략하게 작성해주세요  \n",
    "### 설명\n",
    "\n",
    "'batch_idx' 함수는 주어진 훈련 데이터 'X_train'을 배치 크기 'batch_size'에 따라 나누는 역할을 합니다. \n",
    "\n",
    "1. 전체 데이터의 크기 'N'을 구합니다.\n",
    "2. 배치의 수 'nb'를 계산합니다. 이는 전체 데이터 크기를 배치 크기로 나눈 후 올림한 값입니다.\n",
    "3. 'idx'는 데이터의 인덱스를 저장한 배열입니다.\n",
    "4. 'idx_list'는 배치 크기만큼 인덱스를 나눈 결과를 저장한 리스트입니다. \n",
    "\n",
    "'batch_idx'는 주어진 훈련 데이터를 'batch_size' 크기의 배치로 나누고, 각 배치를 구성하는 데이터의 인덱스를 리스트로 반환합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4pMuZbkQLMa8"
   },
   "source": [
    "## Update Parameters\n",
    "기울기를 갱신하는 코드를 작성해주세요  \n",
    "(loss와 마찬가지로 기울기를 갱신할 때 배치 사이즈를 고려해 평균으로 갱신해주세요)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "loeL51rPLMa8"
   },
   "outputs": [],
   "source": [
    "def step(parameters, gradients, learning_rate, n): #n:현재 배치의 데이터 수\n",
    "    for i in range(len(parameters)):\n",
    "        gradients[i] *= learning_rate / n\n",
    "\n",
    "    parameters -= gradients\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "NLB2dUVTLMa8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.55088641, 0.39150383, 0.57452789])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step(parameters, gradients1, 0.01, len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RX8RJFd_LMa9"
   },
   "source": [
    "## Gradient Descent\n",
    "위에서 작성한 함수들을 조합해서 경사하강법 함수를 완성해주세요\n",
    "\n",
    "- learning_rate: 학습률  \n",
    "- tolerance: Step이 너무 작아서 더 이상의 학습이 무의미할 때 학습을 멈추는 조건  \n",
    "- batch: 기울기를 1번 갱신할 때 사용하는 데이터셋  \n",
    "- epoch:1번의 전체 데이터셋 순회\n",
    "- num_epoch: 전체 데이터셋의 단일 순회 횟수\n",
    "<br>\n",
    "\n",
    "BGD: \"학습 한 번(1 iteration)에 모든 데이터셋을 이용해 기울기를 업데이트\"  \n",
    "SGD: \"학습 한 번(1 iteration)에 1개의 데이터를 이용해 기울기를 업데이트\"  \n",
    "MGD: \"학습 한 번(1 iteration)에 데이터셋의 일부만 사용해 기울기를 업데이트\"  \n",
    "<br>\n",
    "batch_size에 따른 경사하강법의 종류를 적어주세요  \n",
    "batch_size=1 -> \"SGD\"  \n",
    "batch_size=k -> \"MGD\"  \n",
    "batch_size=whole -> \"BGD\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "ZGbnVHbbLMa9"
   },
   "outputs": [],
   "source": [
    "def gradient_descent(X_train, y_train, learning_rate = 0.1, num_epoch = 1000, tolerance = 0.00001, model = 'logistic', batch_size = 16):\n",
    "    stopper = False\n",
    "    \n",
    "    N = len(X_train.iloc[0])\n",
    "    parameters = np.random.rand(N)\n",
    "    loss_function = minus_log_cross_entropy_i if model == 'logistic' else mse_i\n",
    "    loss = 999\n",
    "    batch_idx_list = batch_idx(X_train, batch_size)\n",
    "    \n",
    "    for epoch in range(num_epoch):\n",
    "        if stopper:\n",
    "            break\n",
    "        for idx in batch_idx_list:\n",
    "            X_batch = X_train.iloc[idx,]\n",
    "            y_batch = y_train.iloc[idx]\n",
    "            gradients = batch_gradient(X_batch, y_batch, parameters, model)\n",
    "            parameters = step(parameters, gradients, learning_rate, len(X_batch))\n",
    "            new_loss = batch_loss(X_batch, y_batch, parameters, loss_function, len(X_batch))\n",
    "            \n",
    "            #중단 조건\n",
    "            if abs(new_loss - loss) < tolerance:\n",
    "                stopper = True\n",
    "                break\n",
    "            loss = new_loss\n",
    "        \n",
    "        #100epoch마다 학습 상태 출력\n",
    "        if epoch%100 == 0: #출력이 길게 나오면 check point를 수정해도 됩니다.\n",
    "            print(f\"epoch: {epoch}  loss: {new_loss}  params: {parameters}  gradients: {gradients}\")\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3CTtc3eiLMa9"
   },
   "source": [
    "## Implement\n",
    "경사하강법 함수를 이용해 최적의 모수 찾아보세요. 학습을 진행할 때, Hyper Parameter를 바꿔가면서 학습시켜보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- bs와 model을 바꿔가며 실행\n",
    "    - bgd\n",
    "        - logistic, bs = len(X_train)\n",
    "        - mse_i, bs = len(X_train)\n",
    "    - sgd\n",
    "        - logistic, bs = 1\n",
    "        - mse_i, bs = 1\n",
    "    - mgd\n",
    "        - logistic, bs = 16\n",
    "        - mse_i, bs = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KnUpYC7_LMa9"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "-LS6o3aeLMa-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  loss: 0.4021658936886148  params: [0.38476047 0.02668757 0.10190792]  gradients: [0.03223572162645936, -0.009630275743579147, 0.01238596303017837]\n",
      "epoch: 100  loss: 0.22878179376267255  params: [-0.82533558  0.8336051  -0.76130422]  gradients: [0.0036568914065729357, -0.006556885662699085, 0.0064569043597965045]\n",
      "epoch: 200  loss: 0.19704257485773152  params: [-1.03242281  1.37870366 -1.295535  ]  gradients: [0.0012867181435403433, -0.004559421480959586, 0.004454812138035215]\n",
      "epoch: 300  loss: 0.1813573912771655  params: [-1.13675033  1.77169365 -1.67835614]  gradients: [0.0008864025968413053, -0.003408264069645734, 0.00330867108577219]\n",
      "epoch: 400  loss: 0.17219477790549254  params: [-1.2163949   2.07337803 -1.97030361]  gradients: [0.0007223733123512832, -0.0026830475839698066, 0.0025881558063367257]\n",
      "epoch: 500  loss: 0.16632547091306868  params: [-1.28273523  2.31530588 -2.20304357]  gradients: [0.0006108293270586617, -0.002189240680043741, 0.0021004603199415656]\n",
      "epoch: 600  loss: 0.16232512429269466  params: [-1.33928071  2.51532424 -2.39451358]  gradients: [0.0005242713996185543, -0.0018325003713455985, 0.0017502559112704073]\n",
      "epoch: 700  loss: 0.15947468691807393  params: [-1.38807954  2.68438066 -2.55567029]  gradients: [0.00045484274385658777, -0.001563057560467698, 0.001487191469474109]\n",
      "epoch: 800  loss: 0.15737490937369306  params: [-1.43061256  2.829648   -2.69365712]  gradients: [0.00039824255747387467, -0.0013525294655756623, 0.0012826512312388144]\n",
      "epoch: 900  loss: 0.15578775817324697  params: [-1.46800325  2.95607796 -2.81338221]  gradients: [0.0003514744302832203, -0.0011836302707156706, 0.0011192770300557245]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.50080618,  3.06618855, -2.91737601])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bs = len(X_train)\n",
    "new_param_bgd = gradient_descent(X_train, y_train, learning_rate = 0.1, num_epoch = 1000, model = 'logistic', batch_size = len(X_train))\n",
    "new_param_bgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  loss: 0.32986345981074167  params: [0.92188286 0.25503962 0.06720922]  gradients: [0.04399240480716229, -0.005980229669367146, 0.01457009762136759]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.21632841,  0.37663842, -0.19533089])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bs = len(X_train)\n",
    "new_param_bgd = gradient_descent(X_train, y_train, learning_rate = 0.1, num_epoch = 1000, model = 'mse_i', batch_size = len(X_train))\n",
    "new_param_bgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "x0H5tnauLMa-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  loss: 0.1426977831535967  params: [-0.85829251  0.96697171 -1.102522  ]  gradients: [0.025697307458602395, 0.013984499297625949, 0.018080387616792922]\n",
      "epoch: 100  loss: 0.03868338451606279  params: [-1.93032511  4.17501782 -4.0676896 ]  gradients: [0.007538548565338495, 0.00410248533963834, 0.0053040529771032725]\n",
      "epoch: 200  loss: 0.038681332763079945  params: [-1.9303681   4.1751431  -4.06780374]  gradients: [0.007538159522242799, 0.004102273622013555, 0.005303779249982984]\n",
      "epoch: 300  loss: 0.038681332591808816  params: [-1.9303681   4.17514311 -4.06780375]  gradients: [0.007538159489767171, 0.004102273604340288, 0.0053037792271334325]\n",
      "epoch: 400  loss: 0.038681332591795084  params: [-1.9303681   4.17514311 -4.06780375]  gradients: [0.007538159489764571, 0.004102273604338872, 0.005303779227131603]\n",
      "epoch: 500  loss: 0.038681332591795084  params: [-1.9303681   4.17514311 -4.06780375]  gradients: [0.007538159489764571, 0.004102273604338872, 0.005303779227131603]\n",
      "epoch: 600  loss: 0.038681332591795084  params: [-1.9303681   4.17514311 -4.06780375]  gradients: [0.007538159489764571, 0.004102273604338872, 0.005303779227131603]\n",
      "epoch: 700  loss: 0.038681332591795084  params: [-1.9303681   4.17514311 -4.06780375]  gradients: [0.007538159489764571, 0.004102273604338872, 0.005303779227131603]\n",
      "epoch: 800  loss: 0.038681332591795084  params: [-1.9303681   4.17514311 -4.06780375]  gradients: [0.007538159489764571, 0.004102273604338872, 0.005303779227131603]\n",
      "epoch: 900  loss: 0.038681332591795084  params: [-1.9303681   4.17514311 -4.06780375]  gradients: [0.007538159489764571, 0.004102273604338872, 0.005303779227131603]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.9303681 ,  4.17514311, -4.06780375])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bs = 1\n",
    "new_param_sgd = gradient_descent(X_train, y_train, learning_rate = 0.1, num_epoch = 1000, model = 'logistic', batch_size = 1)\n",
    "new_param_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  loss: 0.6381736215934474  params: [-0.88076548  0.99369735 -1.12247207]  gradients: [0.025265539882772067, 0.013749530969887179, 0.01777659994783377]\n",
      "epoch: 100  loss: 3.175868620239967  params: [-1.93032522  4.17501817 -4.06768992]  gradients: [0.007538547484988165, 0.004102484751710658, 0.005304052216978782]\n",
      "epoch: 200  loss: 3.176007151185473  params: [-1.9303681   4.1751431  -4.06780374]  gradients: [0.007538159522152619, 0.004102273621964479, 0.005303779249919534]\n",
      "epoch: 300  loss: 3.1760071627498365  params: [-1.9303681   4.17514311 -4.06780375]  gradients: [0.007538159489767166, 0.004102273604340285, 0.005303779227133429]\n",
      "epoch: 400  loss: 3.1760071627507633  params: [-1.9303681   4.17514311 -4.06780375]  gradients: [0.007538159489764571, 0.004102273604338872, 0.005303779227131603]\n",
      "epoch: 500  loss: 3.1760071627507633  params: [-1.9303681   4.17514311 -4.06780375]  gradients: [0.007538159489764571, 0.004102273604338872, 0.005303779227131603]\n",
      "epoch: 600  loss: 3.1760071627507633  params: [-1.9303681   4.17514311 -4.06780375]  gradients: [0.007538159489764571, 0.004102273604338872, 0.005303779227131603]\n",
      "epoch: 700  loss: 3.1760071627507633  params: [-1.9303681   4.17514311 -4.06780375]  gradients: [0.007538159489764571, 0.004102273604338872, 0.005303779227131603]\n",
      "epoch: 800  loss: 3.1760071627507633  params: [-1.9303681   4.17514311 -4.06780375]  gradients: [0.007538159489764571, 0.004102273604338872, 0.005303779227131603]\n",
      "epoch: 900  loss: 3.1760071627507633  params: [-1.9303681   4.17514311 -4.06780375]  gradients: [0.007538159489764571, 0.004102273604338872, 0.005303779227131603]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.9303681 ,  4.17514311, -4.06780375])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bs = 1\n",
    "new_param_sgd = gradient_descent(X_train, y_train, learning_rate = 0.1, num_epoch = 1000, model = 'mse_i', batch_size = 1)\n",
    "new_param_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "iGfXGoJaLMa-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  loss: 0.6042477858359293  params: [-0.05304539  0.79558197  0.38305986]  gradients: [0.055796200609354626, 0.05320876229520576, 0.06758636256899303]\n",
      "epoch: 100  loss: 0.09885738057097225  params: [-1.56507007  3.08269866 -3.02962972]  gradients: [0.0073985270992814565, 0.010906941039237766, 0.014491626084235204]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.69619248,  3.53519565, -3.43402924])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bs = 16\n",
    "new_param_mgd = gradient_descent(X_train, y_train, learning_rate = 0.1, num_epoch = 1000, model = 'logistic', batch_size = 16)\n",
    "new_param_mgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  loss: 1.0697132289545792  params: [0.32962964 0.69674245 0.54395892]  gradients: [0.06325314622740646, 0.057989645320860164, 0.07311026980452083]\n",
      "epoch: 100  loss: 2.1668773732044246  params: [-1.56046371  3.06779471 -3.01547369]  gradients: [0.007411368660974976, 0.010916163248357277, 0.014528415505318923]\n",
      "epoch: 200  loss: 2.906180622647143  params: [-1.77341667  3.74568834 -3.65545012]  gradients: [0.0069721349111787284, 0.010562433761358684, 0.013070312068646417]\n",
      "epoch: 300  loss: 3.268414765193743  params: [-1.86820767  4.04222473 -3.93296829]  gradients: [0.006855333571053441, 0.010444711685840836, 0.012554230705747621]\n",
      "epoch: 400  loss: 3.4592069924174638  params: [-1.91613648  4.19131947 -4.07196686]  gradients: [0.006809414284576169, 0.010392400715974495, 0.012318422391816304]\n",
      "epoch: 500  loss: 3.563035143180882  params: [-1.94169636  4.27063056 -4.14576537]  gradients: [0.006787972520926574, 0.010366242206872545, 0.012198933169871947]\n",
      "epoch: 600  loss: 3.620470502675653  params: [-1.95568521  4.31398262 -4.18606315]  gradients: [0.006777057572275306, 0.010352403562473956, 0.012135293424591239]\n",
      "epoch: 700  loss: 3.652518965081203  params: [-1.9634456   4.33801635 -4.20839123]  gradients: [0.006771240600434799, 0.010344866894349826, 0.012100510798919136]\n",
      "epoch: 800  loss: 3.6704863619034254  params: [-1.96778235  4.35144226 -4.22086047]  gradients: [0.006768061922443687, 0.010340697909144856, 0.012081233062505697]\n",
      "epoch: 900  loss: 3.680585800556743  params: [-1.97021565  4.35897389 -4.22785423]  gradients: [0.006766300672017078, 0.010338371999306994, 0.012070466320005644]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.97157387,  4.3631774 , -4.23175718])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bs = 16\n",
    "new_param_mgd = gradient_descent(X_train, y_train, learning_rate = 0.1, num_epoch = 1000, model = 'mse_i', batch_size = 16)\n",
    "new_param_mgd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k0oCaZ0tLMa-"
   },
   "source": [
    "### Predict Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "syJE3oiNLMa-"
   },
   "outputs": [],
   "source": [
    "y_predict = []\n",
    "for i in range(len(y_test)):\n",
    "    p = logistic(X_test.iloc[i,:], new_param_bgd)\n",
    "    if p> 0.5 :\n",
    "        y_predict.append(1)\n",
    "    else :\n",
    "        y_predict.append(0)\n",
    "y_predict_random = []\n",
    "for i in range(len(y_test)):\n",
    "    p = logistic(X_test.iloc[i,:], random_parameters)\n",
    "    if p> 0.5 :\n",
    "        y_predict_random.append(1)\n",
    "    else :\n",
    "        y_predict_random.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZKpFItfLMa-"
   },
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "W4E1PgX5LMa-"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "-veTwxu4LMa-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8, 32],\n",
       "       [ 0, 10]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_predict).ravel()\n",
    "confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "h4_dW9rDLMa_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.36\n"
     ]
    }
   ],
   "source": [
    "accuracy = (tp+tn) / (tp+fn+fp+tn)\n",
    "print(\"accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XIgqa85aLMa_"
   },
   "source": [
    "## Linear regression\n",
    "### $y = 0.5 + 2.7x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYeIg9QNLMa_"
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "nv8-yhszLMa_"
   },
   "outputs": [],
   "source": [
    "raw_X = np.random.rand(150)\n",
    "y = 2.7*raw_X + 0.5 + np.random.randn(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "07XtxLGWLMa_"
   },
   "outputs": [],
   "source": [
    "tmp = np.array([1 for _ in range(150)])\n",
    "X = np.vstack((tmp, raw_X)).T\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.Series(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6oENC02TLMa_"
   },
   "source": [
    "### Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "fu578YrKLMa_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11482172, 3.29101704])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#정규방정식\n",
    "theta = np.linalg.inv(np.dot(X.T,X)).dot(X.T).dot(y)\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "M74iqj4WLMa_",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  loss: -0.2641764770796153  params: [0.35677138 0.90129222]  gradients: [-0.1159442262294915, -0.08364391070419683]\n",
      "epoch: 100  loss: -6.228801014841486  params: [8.83826127 7.76338713]  gradients: [-0.08178274806292696, -0.0673626896572942]\n",
      "epoch: 200  loss: -11.841715935946803  params: [17.01637253 14.49963416]  gradients: [-0.08178091855217137, -0.06736244668504032]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhj98\\AppData\\Local\\Temp\\ipykernel_5876\\3801438891.py:3: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = (-(y * np.log(p) + (1 - y) * np.log(1 - p)))/2\n",
      "C:\\Users\\dhj98\\AppData\\Local\\Temp\\ipykernel_5876\\1343608712.py:21: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if abs(new_loss - loss) < tolerance:\n",
      "C:\\Users\\dhj98\\AppData\\Local\\Temp\\ipykernel_5876\\2221760771.py:6: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  loss += loss_function(X, y, parameters)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 300  loss: nan  params: [25.19446436 21.23587882]  gradients: [-0.08178091828348254, -0.06736244666537959]\n",
      "epoch: 400  loss: nan  params: [33.37255619 27.97212349]  gradients: [-0.08178091828343277, -0.06736244666537701]\n",
      "epoch: 500  loss: nan  params: [41.55064801 34.70836816]  gradients: [-0.08178091828343277, -0.06736244666537701]\n",
      "epoch: 600  loss: nan  params: [49.72873984 41.44461282]  gradients: [-0.08178091828343277, -0.06736244666537701]\n",
      "epoch: 700  loss: nan  params: [57.90683167 48.18085749]  gradients: [-0.08178091828343277, -0.06736244666537701]\n",
      "epoch: 800  loss: nan  params: [66.0849235  54.91710216]  gradients: [-0.08178091828343277, -0.06736244666537701]\n",
      "epoch: 900  loss: nan  params: [74.26301533 61.65334682]  gradients: [-0.08178091828343277, -0.06736244666537701]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([82.35932624, 68.32222904])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#경사하강법(가장 성능이 좋았던 bgd로 진행)\n",
    "new_param = gradient_descent(X, y, learning_rate = 0.1, num_epoch = 1000, model = 'logistic', batch_size = len(X))\n",
    "new_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "Ii3zBOwSLMa_"
   },
   "outputs": [],
   "source": [
    "y_hat_NE = theta.dot(X.T)\n",
    "y_hat_GD = new_param.dot(X.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oCVynFSPLMbA"
   },
   "source": [
    "### Visualization\n",
    "시각화를 통해 정규방정식과 경사하강법을 통한 선형회귀를 비교해보세요  \n",
    "(밑의 코드를 실행만 시키면 됩니다. 추가 코드 x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "UoEACrbYLMbA"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(X.iloc[:,1], y, '.k') #산점도\n",
    "plt.plot(X.iloc[:,1], y_hat_NE, '-b', label = 'NE') #정규방정식\n",
    "plt.plot(X.iloc[:,1], y_hat_GD, '-r', label = 'GD') #경사하강법\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "wk3_optimization_assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
