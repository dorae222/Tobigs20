{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d2StPehwLMat"
   },
   "source": [
    "# Tobig's 19기 2주차 Optimization 과제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DKIX8PqcLMaw"
   },
   "source": [
    "# Gradient Descent 구현하기\n",
    "\n",
    "### 1)\"...\"표시되어 있는 빈 칸을 채워주세요\n",
    "### 2)강의내용과 코드에 대해 공부한 내용을 마크마운 또는 주석으로 설명해주세요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6DNHHXfLMax"
   },
   "source": [
    "## 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EP3O4xptLMay"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oByQ9wXHLMay"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>bias</th>\n",
       "      <th>experience</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>63000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>76000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label  bias  experience  salary\n",
       "0      1     1         0.7   48000\n",
       "1      0     1         1.9   48000\n",
       "2      1     1         2.5   60000\n",
       "3      0     1         4.2   63000\n",
       "4      0     1         6.0   76000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('assignment_2.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ubOR3hWGLMaz"
   },
   "source": [
    "## Train Test 데이터 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "IySSjlizLMaz"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "075EQI1bLMa0"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:, 0], test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "O8Ht5u8kLMa1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 3), (50, 3), (150,), (50,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hYmxND_xLMa2"
   },
   "source": [
    "## Scaling\n",
    "\n",
    "experience와 salary의 단위, 평균, 분산이 크게 차이나므로 scaler를 사용해 단위를 맞춰줍니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "UI0Xy0gHLMa3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>experience</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.187893</td>\n",
       "      <td>-1.143335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.185555</td>\n",
       "      <td>0.043974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.310938</td>\n",
       "      <td>-0.351795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.629277</td>\n",
       "      <td>-1.341220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.308600</td>\n",
       "      <td>0.043974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bias  experience    salary\n",
       "0     1    0.187893 -1.143335\n",
       "1     1    1.185555  0.043974\n",
       "2     1   -0.310938 -0.351795\n",
       "3     1   -1.629277 -1.341220\n",
       "4     1   -1.308600  0.043974"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "bias_train = X_train[\"bias\"]\n",
    "bias_train = bias_train.reset_index()[\"bias\"]\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns = X_train.columns)\n",
    "X_train[\"bias\"] = bias_train\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xD7L7RwZLMa3"
   },
   "source": [
    "이때 scaler는 X_train에 fit 해주시고, fit한 scaler를 X_test에 적용시켜줍니다.  \n",
    "똑같이 X_test에다 fit하면 안돼요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "xBsUSCGGLMa3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>experience</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.344231</td>\n",
       "      <td>-0.615642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.508570</td>\n",
       "      <td>0.307821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.310938</td>\n",
       "      <td>0.571667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.363709</td>\n",
       "      <td>1.956862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.987923</td>\n",
       "      <td>-0.747565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bias  experience    salary\n",
       "0     1   -1.344231 -0.615642\n",
       "1     1    0.508570  0.307821\n",
       "2     1   -0.310938  0.571667\n",
       "3     1    1.363709  1.956862\n",
       "4     1   -0.987923 -0.747565"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_test = X_test[\"bias\"]\n",
    "bias_test = bias_test.reset_index()[\"bias\"]\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns = X_test.columns)\n",
    "X_test[\"bias\"] = bias_test\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "m9sP3nzlLMa4"
   },
   "outputs": [],
   "source": [
    "# parameter 개수\n",
    "N = len(X_train.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "qz7xz9dbLMa4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02837581, 0.28340219, 0.74096711])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 초기 parameter들을 임의로 설정해줍니다.\n",
    "parameters = np.array([random.random() for i in range(N)])\n",
    "random_parameters = parameters.copy()\n",
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QINz-EAKLMa4"
   },
   "source": [
    "### * LaTeX   \n",
    "\n",
    "Jupyter Notebook은 LaTeX 문법으로 수식 입력을 지원하고 있습니다.  \n",
    "LaTeX문법으로 아래의 수식을 완성해주세요  \n",
    "http://triki.net/apps/3466  \n",
    "https://jjycjnmath.tistory.com/117"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D2DsTfXuLMa5"
   },
   "source": [
    "## Dot product\n",
    "## $z = X_i \\theta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "2y05lS6xLMa5"
   },
   "outputs": [],
   "source": [
    "def dot_product(X, parameters):\n",
    "    z = 0\n",
    "    for i in range(len(parameters)):\n",
    "        z += X[i] * parameters[i]\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fOGPEhtOLMa5"
   },
   "source": [
    "## Logistic Function\n",
    "\n",
    "## $p = \"...\"$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "2awM57u5LMa5"
   },
   "outputs": [],
   "source": [
    "def logistic(X, parameters):\n",
    "    z = dot_product(X, parameters)\n",
    "    p = 1 / (1 + np.exp(-z))    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "WVaZEwrdLMa5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5979542501672273"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic(X_train.iloc[1], parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E6cXHl8bLMa6"
   },
   "source": [
    "## Object function\n",
    "\n",
    "Object Function : 목적함수는 Gradient Descent를 통해 최적화 하고자 하는 함수입니다.  \n",
    "<br>\n",
    "선형 회귀의 목적함수\n",
    "## $l(\\theta) = \\frac{1}{2}\\Sigma(y_i - \\theta^{T}X_i)^2$  \n",
    "참고) $\\hat{y_i} = \\theta^{T}X_i$\n",
    "  \n",
    "로지스틱 회귀의 목적함수를 작성해주세요  \n",
    "(선형 회귀의 목적함수처럼 강의에 나온대로 작성해주세요. 평균을 고려하는 것은 뒤에 코드에서 수행합니다)\n",
    "## $l(p)= \\frac{1}{2}\\Sigma(-y_{i}log(\\theta^{T}X_i)-(1-y_{i})log(1-\\theta^{T}X_i))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "FnGRAur3LMa6"
   },
   "outputs": [],
   "source": [
    "def minus_log_cross_entropy_i(X, y, parameters):\n",
    "    p = logistic(X, parameters)\n",
    "    loss = (-(y * np.log(p) + (1 - y) * np.log(1 - p)))/2\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "C922eXYyLMa6"
   },
   "outputs": [],
   "source": [
    "def mse_i(X, y, parameters):\n",
    "    y_hat = dot_product(X, parameters)\n",
    "    loss = (y - y_hat) ** 2 / 2\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "0j-MhGkyLMa6"
   },
   "outputs": [],
   "source": [
    "def batch_loss(X_set, y_set, parameters, loss_function, n): #n:현재 배치의 데이터 수\n",
    "    loss = 0\n",
    "    for i in range(X_set.shape[0]):\n",
    "        X = X_set.iloc[i,:]\n",
    "        y = y_set.iloc[i]\n",
    "        loss += loss_function(X, y, parameters)\n",
    "    loss = loss/n #loss 평균값으로 계산\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "uSkPS5olLMa7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4793152790920594"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_loss(X_test, y_test, parameters, minus_log_cross_entropy_i, len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ACLi9vCyLMa7"
   },
   "source": [
    "## Gradient\n",
    "위의 선형회귀의 목적함수 $l(\\theta)$와 로지스틱회귀의 목적함수 $l(p)$의 gradient를 작성해주세요  \n",
    "(위의 목적함수를 참고해서 작성해주세요 = 평균을 고려하는 것은 뒤에 코드에서 수행합니다)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "caMA-f00LMa7"
   },
   "source": [
    "## ${\\partial\\over{\\partial \\theta_j}}l(\\theta)=$ $\\sum (y_i - \\theta^{T}X_i)(-X_{ij})$\n",
    "## ${\\partial\\over{\\partial \\theta_j}}l(p)=$ $\\sum (y_i - p_i)(-X_{ij})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "apZ0Miz5LMa7"
   },
   "outputs": [],
   "source": [
    "def get_gradient_ij(X, y, parameters, j, model):\n",
    "    if model == 'linear':\n",
    "        y_hat = dot_product(X, parameters)\n",
    "        gradient = -(y - y_hat) * X[j]\n",
    "    else:  # model == 'logistic'\n",
    "        p = logistic(X, parameters)\n",
    "        gradient = (p - y) * X[j]\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "XXBe6q8gLMa7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.12824773937329847"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_gradient_ij(X_train.iloc[0,:], y_train.iloc[0], parameters, 1, 'logistic')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"./img/배치알고리즘구현.png\" width=\"500\"/><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wTfzKh_nLMa7"
   },
   "source": [
    "## Batch Gradient\n",
    "하나의 배치 (X_set, y_set)에 대해 기울기를 구하는 코드를 작성해주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Qby2_X1vLMa7"
   },
   "outputs": [],
   "source": [
    "def batch_gradient(X_set, y_set, parameters, model):\n",
    "    gradients = [0 for _ in range(len(parameters))]\n",
    "    \n",
    "    for i in range(X_set.shape[0]):\n",
    "        X = X_set.iloc[i,:]\n",
    "        y = y_set.iloc[i]\n",
    "        for j in range(len(parameters)):\n",
    "            gradients[j] += get_gradient_ij(X, y, parameters, j, model)\n",
    "    \n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "rHxBS5RnLMa8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[33.41797531331254, 8.82982734341497, 44.252933169888]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients1 = batch_gradient(X_train, y_train, parameters, 'logistic')\n",
    "gradients1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQnlDboALMa8"
   },
   "source": [
    "## mini-batch\n",
    "인덱스로 미니 배치 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "LgnfT6eHLMa8"
   },
   "outputs": [],
   "source": [
    "def batch_idx(X_train, batch_size):\n",
    "    N = len(X_train)\n",
    "    nb = (N // batch_size)+1 #number of batch\n",
    "    idx = np.array([i for i in range(N)])\n",
    "    idx_list = [idx[i*batch_size:(i+1)*batch_size] for i in range(nb) if len(idx[i*batch_size:(i+1)*batch_size]) != 0]\n",
    "    return idx_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9S9fk1UTLMa8"
   },
   "source": [
    "batch_idx 함수에 대한 설명을 batch_size와 함께 간략하게 작성해주세요  \n",
    "### 설명\n",
    "\n",
    "'batch_idx' 함수는 주어진 훈련 데이터 'X_train'을 배치 크기 'batch_size'에 따라 나누는 역할을 합니다. \n",
    "\n",
    "1. 전체 데이터의 크기 'N'을 구합니다.\n",
    "2. 배치의 수 'nb'를 계산합니다. 이는 전체 데이터 크기를 배치 크기로 나눈 후 올림한 값입니다.\n",
    "3. 'idx'는 데이터의 인덱스를 저장한 배열입니다.\n",
    "4. 'idx_list'는 배치 크기만큼 인덱스를 나눈 결과를 저장한 리스트입니다. \n",
    "\n",
    "'batch_idx'는 주어진 훈련 데이터를 'batch_size' 크기의 배치로 나누고, 각 배치를 구성하는 데이터의 인덱스를 리스트로 반환합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4pMuZbkQLMa8"
   },
   "source": [
    "## Update Parameters\n",
    "기울기를 갱신하는 코드를 작성해주세요  \n",
    "(loss와 마찬가지로 기울기를 갱신할 때 배치 사이즈를 고려해 평균으로 갱신해주세요)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "loeL51rPLMa8"
   },
   "outputs": [],
   "source": [
    "def step(parameters, gradients, learning_rate, n): #n:현재 배치의 데이터 수\n",
    "    for i in range(len(parameters)):\n",
    "        gradients[i] *= learning_rate / n\n",
    "\n",
    "    parameters -= gradients\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "NLB2dUVTLMa8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02614795, 0.28281354, 0.73801691])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step(parameters, gradients1, 0.01, len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RX8RJFd_LMa9"
   },
   "source": [
    "## Gradient Descent\n",
    "위에서 작성한 함수들을 조합해서 경사하강법 함수를 완성해주세요\n",
    "\n",
    "- learning_rate: 학습률  \n",
    "- tolerance: Step이 너무 작아서 더 이상의 학습이 무의미할 때 학습을 멈추는 조건  \n",
    "- batch: 기울기를 1번 갱신할 때 사용하는 데이터셋  \n",
    "- epoch:1번의 전체 데이터셋 순회\n",
    "- num_epoch: 전체 데이터셋의 단일 순회 횟수\n",
    "<br>\n",
    "\n",
    "BGD: \"학습 한 번(1 iteration)에 모든 데이터셋을 이용해 기울기를 업데이트\"  \n",
    "SGD: \"학습 한 번(1 iteration)에 1개의 데이터를 이용해 기울기를 업데이트\"  \n",
    "MGD: \"학습 한 번(1 iteration)에 데이터셋의 일부만 사용해 기울기를 업데이트\"  \n",
    "<br>\n",
    "batch_size에 따른 경사하강법의 종류를 적어주세요  \n",
    "batch_size=1 -> \"SGD\"  \n",
    "batch_size=k -> \"MGD\"  \n",
    "batch_size=whole -> \"BGD\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "ZGbnVHbbLMa9"
   },
   "outputs": [],
   "source": [
    "def gradient_descent(X_train, y_train, learning_rate = 0.1, num_epoch = 1000, tolerance = 0.00001, model = 'logistic', batch_size = 16):\n",
    "    stopper = False\n",
    "    \n",
    "    N = len(X_train.iloc[0])\n",
    "    parameters = np.random.rand(N)\n",
    "    loss_function = minus_log_cross_entropy_i if model == 'logistic' else mse_i\n",
    "    loss = 999\n",
    "    batch_idx_list = batch_idx(X_train, batch_size)\n",
    "    \n",
    "    for epoch in range(num_epoch):\n",
    "        if stopper:\n",
    "            break\n",
    "        for idx in batch_idx_list:\n",
    "            X_batch = X_train.iloc[idx,]\n",
    "            y_batch = y_train.iloc[idx]\n",
    "            gradients = batch_gradient(X_batch, y_batch, parameters, model)\n",
    "            parameters = step(parameters, gradients, learning_rate, len(X_batch))\n",
    "            new_loss = batch_loss(X_batch, y_batch, parameters, loss_function, len(X_batch))\n",
    "            \n",
    "            #중단 조건\n",
    "            if abs(new_loss - loss) < tolerance:\n",
    "                stopper = True\n",
    "                break\n",
    "            loss = new_loss\n",
    "        \n",
    "        #100epoch마다 학습 상태 출력\n",
    "        if epoch%100 == 0: #출력이 길게 나오면 check point를 수정해도 됩니다.\n",
    "            print(f\"epoch: {epoch}  loss: {new_loss}  params: {parameters}  gradients: {gradients}\")\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3CTtc3eiLMa9"
   },
   "source": [
    "## Implement\n",
    "경사하강법 함수를 이용해 최적의 모수 찾아보세요. 학습을 진행할 때, Hyper Parameter를 바꿔가면서 학습시켜보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- bs와 model을 바꿔가며 실행\n",
    "    - bgd\n",
    "        - logistic, bs = len(X_train)\n",
    "        - mse_i, bs = len(X_train)\n",
    "    - sgd\n",
    "        - logistic, bs = 1\n",
    "        - mse_i, bs = 1\n",
    "    - mgd\n",
    "        - logistic, bs = 16\n",
    "        - mse_i, bs = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KnUpYC7_LMa9"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "-LS6o3aeLMa-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  loss: 0.5112822673086386  params: [0.76445286 0.14238737 0.5942951 ]  gradients: [0.03913379550368566, -0.00026148197484726485, 0.02345427109486312]\n",
      "epoch: 100  loss: 0.237019184223578  params: [-0.78031363  0.72857333 -0.64761566]  gradients: [0.004351519621024282, -0.00685178787550589, 0.007145106213127092]\n",
      "epoch: 200  loss: 0.20058930796445568  params: [-1.01391768  1.30391063 -1.22198945]  gradients: [0.0013687172040901462, -0.004806316602186472, 0.004712581442177354]\n",
      "epoch: 300  loss: 0.183295993109268  params: [-1.12284437  1.71611694 -1.62434327]  gradients: [0.0009148836582256053, -0.0035570009689615055, 0.003457587287653997]\n",
      "epoch: 400  loss: 0.1733840016130355  params: [-1.20480459  2.02980132 -1.92824611]  gradients: [0.0007420063012870483, -0.0027801069858872465, 0.0026844121555701836]\n",
      "epoch: 500  loss: 0.1671118543017419  params: [-1.27288556  2.27983854 -2.16900151]  gradients: [0.0006263229369319368, -0.002257207246417486, 0.0021674062613488126]\n",
      "epoch: 600  loss: 0.16287314789006233  params: [-1.33082056  2.48568748 -2.36619802]  gradients: [0.0005367307336423411, -0.001882662727312454, 0.001799375692914801]\n",
      "epoch: 700  loss: 0.15987160908594134  params: [-1.38074197  2.65913347 -2.53164208]  gradients: [0.0004649592317480527, -0.0016015667222084005, 0.0015247046898153593]\n",
      "epoch: 800  loss: 0.15767096694192118  params: [-1.42419141  2.80782249 -2.67295443]  gradients: [0.000406550269664291, -0.0013829996718267483, 0.0013121954464488299]\n",
      "epoch: 900  loss: 0.15601373776303465  params: [-1.46233914  2.93699256 -2.79533083]  gradients: [0.0003583800246078176, -0.0012083194431086253, 0.0011431155695662354]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.49576922,  3.04932454, -2.90146548])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bs = len(X_train)\n",
    "new_param_bgd = gradient_descent(X_train, y_train, learning_rate = 0.1, num_epoch = 1000, model = 'logistic', batch_size = len(X_train))\n",
    "new_param_bgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  loss: 0.24240293548464323  params: [0.4045131  0.0810173  0.39785183]  gradients: [0.03216302593373795, -0.0032487960036443153, 0.020116345798852645]\n",
      "epoch: 100  loss: 0.6868662243177143  params: [-0.81878959  0.76808794 -0.69035007]  gradients: [0.003632528014003915, -0.006771303012442046, 0.006897510837229743]\n",
      "epoch: 200  loss: 1.106144497540457  params: [-1.02405801  1.33292747 -1.25042274]  gradients: [0.0012819993307874758, -0.004713569199018178, 0.004617512539384812]\n",
      "epoch: 300  loss: 1.4705187131215898  params: [-1.12875931  1.73777582 -1.64538416]  gradients: [0.000895197090015413, -0.0034992641673014385, 0.003400067377574485]\n",
      "epoch: 400  loss: 1.8118879033956152  params: [-1.20941152  2.0467813  -1.94463692]  gradients: [0.000732779155611792, -0.0027421519989752853, 0.002646797911096781]\n",
      "epoch: 500  loss: 2.1275274941229902  params: [-1.27673608  2.29364557 -2.18225672]  gradients: [0.0006199583867384634, -0.0022306120579058744, 0.002141206938607725]\n",
      "epoch: 600  loss: 2.4165996195311408  params: [-1.33411278  2.49721404 -2.37721298]  gradients: [0.0005318013617094508, -0.0018630548423830891, 0.0017801704644789835]\n",
      "epoch: 700  loss: 2.6804497539995986  params: [-1.38359288  2.66894527 -2.5409818 ]  gradients: [0.000461000284008564, -0.001586533428812784, 0.001510056610488342]\n",
      "epoch: 800  loss: 2.921233666211641  params: [-1.42668444  2.81629931 -2.68099638]  gradients: [0.0004033110048153522, -0.0013711186173405645, 0.0013006729273961051]\n",
      "epoch: 900  loss: 3.1412351660633906  params: [-1.46453724  2.94440149 -2.80233927]  gradients: [0.00035569157998315687, -0.0011987020956133957, 0.0011338277486383256]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.49772327,  3.0558685 , -2.90764017])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bs = len(X_train)\n",
    "new_param_bgd = gradient_descent(X_train, y_train, learning_rate = 0.1, num_epoch = 1000, model = 'mse_i', batch_size = len(X_train))\n",
    "new_param_bgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "x0H5tnauLMa-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  loss: 0.14100190985087824  params: [-0.86204411  1.05390639 -1.18394695]  gradients: [0.02542680879233122, 0.013837293664717835, 0.01789006725953809]\n",
      "epoch: 100  loss: 0.038683365623396235  params: [-1.9303255   4.17501898 -4.06769065]  gradients: [0.0075385449830113116, 0.004102483390132461, 0.005304050456611032]\n",
      "epoch: 200  loss: 0.03868133276150311  params: [-1.9303681   4.1751431  -4.06780374]  gradients: [0.007538159521943802, 0.004102273621850841, 0.005303779249772613]\n",
      "epoch: 300  loss: 0.0386813325918087  params: [-1.9303681   4.17514311 -4.06780375]  gradients: [0.007538159489767153, 0.004102273604340278, 0.00530377922713342]\n",
      "epoch: 400  loss: 0.038681332591795084  params: [-1.9303681   4.17514311 -4.06780375]  gradients: [0.007538159489764571, 0.004102273604338872, 0.005303779227131603]\n",
      "epoch: 500  loss: 0.038681332591795084  params: [-1.9303681   4.17514311 -4.06780375]  gradients: [0.007538159489764571, 0.004102273604338872, 0.005303779227131603]\n",
      "epoch: 600  loss: 0.038681332591795084  params: [-1.9303681   4.17514311 -4.06780375]  gradients: [0.007538159489764571, 0.004102273604338872, 0.005303779227131603]\n",
      "epoch: 700  loss: 0.038681332591795084  params: [-1.9303681   4.17514311 -4.06780375]  gradients: [0.007538159489764571, 0.004102273604338872, 0.005303779227131603]\n",
      "epoch: 800  loss: 0.038681332591795084  params: [-1.9303681   4.17514311 -4.06780375]  gradients: [0.007538159489764571, 0.004102273604338872, 0.005303779227131603]\n",
      "epoch: 900  loss: 0.038681332591795084  params: [-1.9303681   4.17514311 -4.06780375]  gradients: [0.007538159489764571, 0.004102273604338872, 0.005303779227131603]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.9303681 ,  4.17514311, -4.06780375])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bs = 1\n",
    "new_param_sgd = gradient_descent(X_train, y_train, learning_rate = 0.1, num_epoch = 1000, model = 'logistic', batch_size = 1)\n",
    "new_param_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  loss: 0.5782420495248112  params: [-0.83475437  0.89179421 -1.03179356]  gradients: [0.026343050867337903, 0.014335913478292779, 0.01853472670075087]\n",
      "epoch: 100  loss: 3.1758671433348686  params: [-1.93032477  4.17501684 -4.06768871]  gradients: [0.007538551621280336, 0.0041024870026848135, 0.00530405512723566]\n",
      "epoch: 200  loss: 3.1760071510621763  params: [-1.9303681   4.1751431  -4.06780374]  gradients: [0.007538159522497902, 0.004102273622152383, 0.005303779250162472]\n",
      "epoch: 300  loss: 3.176007162749822  params: [-1.9303681   4.17514311 -4.06780375]  gradients: [0.007538159489767206, 0.004102273604340306, 0.005303779227133458]\n",
      "epoch: 400  loss: 3.1760071627507633  params: [-1.9303681   4.17514311 -4.06780375]  gradients: [0.007538159489764571, 0.004102273604338872, 0.005303779227131603]\n",
      "epoch: 500  loss: 3.1760071627507633  params: [-1.9303681   4.17514311 -4.06780375]  gradients: [0.007538159489764571, 0.004102273604338872, 0.005303779227131603]\n",
      "epoch: 600  loss: 3.1760071627507633  params: [-1.9303681   4.17514311 -4.06780375]  gradients: [0.007538159489764571, 0.004102273604338872, 0.005303779227131603]\n",
      "epoch: 700  loss: 3.1760071627507633  params: [-1.9303681   4.17514311 -4.06780375]  gradients: [0.007538159489764571, 0.004102273604338872, 0.005303779227131603]\n",
      "epoch: 800  loss: 3.1760071627507633  params: [-1.9303681   4.17514311 -4.06780375]  gradients: [0.007538159489764571, 0.004102273604338872, 0.005303779227131603]\n",
      "epoch: 900  loss: 3.1760071627507633  params: [-1.9303681   4.17514311 -4.06780375]  gradients: [0.007538159489764571, 0.004102273604338872, 0.005303779227131603]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.9303681 ,  4.17514311, -4.06780375])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bs = 1\n",
    "new_param_sgd = gradient_descent(X_train, y_train, learning_rate = 0.1, num_epoch = 1000, model = 'mse_i', batch_size = 1)\n",
    "new_param_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "iGfXGoJaLMa-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  loss: 0.7273923603344071  params: [0.51672376 0.63689867 0.3886247 ]  gradients: [0.06398723085925156, 0.057989175176897306, 0.07284795588777629]\n",
      "epoch: 100  loss: 0.09913555276187987  params: [-1.56170357  3.07180787 -3.01928585]  gradients: [0.007407895673926803, 0.01091367400182752, 0.014518487231155197]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.69614854,  3.53505687, -3.43389816])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bs = 16\n",
    "new_param_mgd = gradient_descent(X_train, y_train, learning_rate = 0.1, num_epoch = 1000, model = 'logistic', batch_size = 16)\n",
    "new_param_mgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  loss: 0.7330115803047134  params: [0.28462876 0.53267424 0.47260543]  gradients: [0.05995641724825217, 0.055145408175523124, 0.07028188329381199]\n",
      "epoch: 100  loss: 2.1625306004807068  params: [-1.55911557  3.06343011 -3.01132737]  gradients: [0.007415159645757658, 0.010918876604613803, 0.014539232590692482]\n",
      "epoch: 200  loss: 2.9041609540102047  params: [-1.7728729   3.74398    -3.65384716]  gradients: [0.006972918999183556, 0.010563169813704065, 0.013073479399253017]\n",
      "epoch: 300  loss: 3.267374904546566  params: [-1.86794289  4.04139961 -3.93219806]  gradients: [0.006855609533246799, 0.010445013183181917, 0.012555577810484263]\n",
      "epoch: 400  loss: 3.458647291404302  params: [-1.91599773  4.19088856 -4.07156563]  gradients: [0.006809536188551604, 0.010392545897767258, 0.012319082626033878]\n",
      "epoch: 500  loss: 3.5627272908258507  params: [-1.9416211   4.27039721 -4.14554839]  gradients: [0.006788032774435906, 0.010366317558727346, 0.012199278883274418]\n",
      "epoch: 600  loss: 3.6202992509726744  params: [-1.95564365  4.31385389 -4.18594354]  gradients: [0.0067770891709767345, 0.010352444185441984, 0.012135480668327226]\n",
      "epoch: 700  loss: 3.6524231181051103  params: [-1.96342244  4.33794464 -4.20832462]  gradients: [0.006771257714236757, 0.010344889241306466, 0.012100614061476606]\n",
      "epoch: 800  loss: 3.6704325371484305  params: [-1.96776937  4.35140209 -4.22082317]  gradients: [0.006768071357804418, 0.010340710338546505, 0.012081290576584828]\n",
      "epoch: 900  loss: 3.680555517594872  params: [-1.97020836  4.35895132 -4.22783328]  gradients: [0.006766305925952272, 0.010338378954854371, 0.012070498529857912]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.97156974,  4.36316463, -4.23174532])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bs = 16\n",
    "new_param_mgd = gradient_descent(X_train, y_train, learning_rate = 0.1, num_epoch = 1000, model = 'mse_i', batch_size = 16)\n",
    "new_param_mgd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k0oCaZ0tLMa-"
   },
   "source": [
    "### Predict Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "syJE3oiNLMa-"
   },
   "outputs": [],
   "source": [
    "y_predict = []\n",
    "for i in range(len(y_test)):\n",
    "    p = logistic(X_test.iloc[i,:], new_param_bgd)\n",
    "    if p> 0.5 :\n",
    "        y_predict.append(1)\n",
    "    else :\n",
    "        y_predict.append(0)\n",
    "y_predict_random = []\n",
    "for i in range(len(y_test)):\n",
    "    p = logistic(X_test.iloc[i,:], random_parameters)\n",
    "    if p> 0.5 :\n",
    "        y_predict_random.append(1)\n",
    "    else :\n",
    "        y_predict_random.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZKpFItfLMa-"
   },
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "W4E1PgX5LMa-"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "-veTwxu4LMa-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[38,  2],\n",
       "       [ 4,  6]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_predict).ravel()\n",
    "confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "h4_dW9rDLMa_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "accuracy = (tp+tn) / (tp+fn+fp+tn)\n",
    "print(\"accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XIgqa85aLMa_"
   },
   "source": [
    "## Linear regression\n",
    "### $y = 0.5 + 2.7x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYeIg9QNLMa_"
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "nv8-yhszLMa_"
   },
   "outputs": [],
   "source": [
    "raw_X = np.random.rand(150)\n",
    "y = 2.7*raw_X + 0.5 + np.random.randn(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "07XtxLGWLMa_"
   },
   "outputs": [],
   "source": [
    "tmp = np.array([1 for _ in range(150)])\n",
    "X = np.vstack((tmp, raw_X)).T\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.Series(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6oENC02TLMa_"
   },
   "source": [
    "### Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "fu578YrKLMa_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.62431544, 2.54436027])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#정규방정식\n",
    "theta = np.linalg.inv(np.dot(X.T,X)).dot(X.T).dot(y)\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "M74iqj4WLMa_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhj98\\AppData\\Local\\Temp\\ipykernel_30176\\1343608712.py:6: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  loss_function = minus_log_cross_entropy_i if model == 'logistic' else mse_i\n",
      "C:\\Users\\dhj98\\AppData\\Local\\Temp\\ipykernel_30176\\3779599136.py:2: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if model == 'linear':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  loss: 0.3830986394874411  params: [1.57939104 1.13307121]  gradients: [-0.14126308189458628, -0.10855808379012842]\n",
      "epoch: 100  loss: 9828.90137883321  params: [98.16553114 73.52701737]  gradients: [-0.12918364429841453, -0.10277977828899708]\n",
      "epoch: 200  loss: 39321.501953284926  params: [194.65729948 145.88364403]  gradients: [-0.12918364429841453, -0.10277977828899708]\n",
      "epoch: 300  loss: 88478.17872781138  params: [291.14906781 218.24027069]  gradients: [-0.12918364429841453, -0.10277977828899708]\n",
      "epoch: 400  loss: 157298.93170241325  params: [387.64083614 290.59689735]  gradients: [-0.12918364429841453, -0.10277977828899708]\n",
      "epoch: 500  loss: 245783.76087708864  params: [484.13260447 362.95352401]  gradients: [-0.12918364429841453, -0.10277977828899708]\n",
      "epoch: 600  loss: 353932.66625183163  params: [580.62437281 435.31015067]  gradients: [-0.12918364429841453, -0.10277977828899708]\n",
      "epoch: 700  loss: 481745.6478266434  params: [677.11614114 507.66677733]  gradients: [-0.12918364429841453, -0.10277977828899708]\n",
      "epoch: 800  loss: 629222.7056015152  params: [773.60790947 580.02340399]  gradients: [-0.12918364429841453, -0.10277977828899708]\n",
      "epoch: 900  loss: 796363.8395764547  params: [870.09967781 652.38003064]  gradients: [-0.12918364429841453, -0.10277977828899708]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([965.62652845, 724.01309104])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#경사하강법\n",
    "new_param = gradient_descent(X, y, learning_rate = 0.1, num_epoch = 1000, model = theta, batch_size = 16)\n",
    "new_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "Ii3zBOwSLMa_"
   },
   "outputs": [],
   "source": [
    "y_hat_NE = theta.dot(X.T)\n",
    "y_hat_GD = new_param.dot(X.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oCVynFSPLMbA"
   },
   "source": [
    "### Visualization\n",
    "시각화를 통해 정규방정식과 경사하강법을 통한 선형회귀를 비교해보세요  \n",
    "(밑의 코드를 실행만 시키면 됩니다. 추가 코드 x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "UoEACrbYLMbA"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(X.iloc[:,1], y, '.k') #산점도\n",
    "plt.plot(X.iloc[:,1], y_hat_NE, '-b', label = 'NE') #정규방정식\n",
    "plt.plot(X.iloc[:,1], y_hat_GD, '-r', label = 'GD') #경사하강법\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "wk3_optimization_assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
